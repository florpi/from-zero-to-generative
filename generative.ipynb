{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/florpi/summer_school_generative/blob/main/3_diffusion_models.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jax jaxlib flax torchvision torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cuda(id=0)]\n"
     ]
    }
   ],
   "source": [
    "# as opposed to pytorch, jax handles device placement automatically\n",
    "# Now let's check wehther you are actually using a gpu, if so, the output should be a cuda id, otherwise you are using a cpu\n",
    "import jax\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    (\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5,), (0.5,)), \n",
    "        transforms.Lambda(lambda x: np.transpose(np.array(x), (1,2,0))), \n",
    "    )\n",
    ")\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "train_loader = iter(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ From Classification to Generation: Flow Matching\n",
    "\n",
    "We've mastered classifying digits, but now it's time to flip the script. Instead of recognizing numbers, we're going to create them.\n",
    "\n",
    "### ðŸŒŠ Flow Matching\n",
    "\n",
    "We're going to learn a process that gradually transforms random noise into digit images. Let's break down the key equations:\n",
    "\n",
    "1. **Velocity Ordinary Differential Equation (ODE)**:\n",
    "   At the heart of Flow Matching is this equation:\n",
    "\n",
    "   $\\frac{dx_t}{dt} = v_\\theta(x_t, t)$\n",
    "\n",
    "   Where:\n",
    "   - $x_t$ is our image as it's being transformed\n",
    "   - $t$ is time (0 to 1)\n",
    "   - $v_\\theta$ is a velocity field we'll learn (it will be the output of our model)\n",
    "\n",
    "2. **Linear Interpolation**:\n",
    "   We chose an x_t that obeys:\n",
    "\n",
    "   $x_t = (1-t)x_0 + tx_1$\n",
    "\n",
    "   Where:\n",
    "   - $x_0$ is random noise (our starting point)\n",
    "   - $x_1$ is a real digit image (our target) \n",
    "\n",
    "3. **Loss Function**:\n",
    "   We train our model to minimize:\n",
    "\n",
    "   $L = \\mathbb{E}_{t,x_0,x_1} \\left[ \\left\\| v_\\theta(x_t, t) - u(x_0,x_1,t) \\right\\|^2 \\right]$\n",
    "\n",
    "   Where, given the linear interpolant, the true velocity field is $u(x_0, x_1,t) = x_1 - x_0$, This teaches our model to predict the right direction of change at each step.\n",
    "\n",
    "\n",
    "We'll create a neural network that learns this vector field v. Once trained, we can use it to generate new MNIST-like digits by:\n",
    "1. Starting with random noise\n",
    "2. Following the learned flow to transform the noise into a digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VelocityModel(nn.Module):\n",
    "    backbone: nn.Module\n",
    "    d_t_embedding: int = 32\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x_t, t,):\n",
    "        t_embedding = self.get_timestep_embedding(\n",
    "            t, self.d_t_embedding\n",
    "        )  \n",
    "        return self.backbone(x_t, t_embedding,)\n",
    "\n",
    "    def get_timestep_embedding(self, timesteps, embedding_dim: int, dtype=jnp.float32):\n",
    "        \"\"\"Build sinusoidal embeddings (from Fairseq).\"\"\"\n",
    "\n",
    "        assert len(timesteps.shape) == 1\n",
    "        timesteps *= 1000\n",
    "\n",
    "        half_dim = embedding_dim // 2\n",
    "        emb = jnp.log(10_000) / (half_dim - 1)\n",
    "        emb = jnp.exp(jnp.arange(half_dim, dtype=dtype) * -emb)\n",
    "        emb = timesteps.astype(dtype)[:, None] * emb[None, :]\n",
    "        emb = jnp.concatenate([jnp.sin(emb), jnp.cos(emb)], axis=1)\n",
    "        if embedding_dim % 2 == 1:  # Zero pad\n",
    "            emb = jax.lax.pad(emb, dtype(0), ((0, 0, 0), (0, 1, 0)))\n",
    "        assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "        return emb.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify the MLP used before, since now we will need to output an array of the same shape as our input for the velocity field. In this case, it will be (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write architecutre\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    input_shape: tuple  # The shape of the input images\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, t):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape((batch_size, -1))  # Flatten the input\n",
    "        x = jnp.concatenate([x, t], axis=-1)\n",
    "        x = nn.Dense(features=1024)(x)\n",
    "        x = nn.silu(x)\n",
    "        x = nn.Dense(features=1024)(x)\n",
    "        x = nn.silu(x)\n",
    "        x = nn.Dense(features=1024)(x)\n",
    "        x = nn.silu(x)\n",
    "        x = nn.Dense(features=1024)(x)\n",
    "        x = nn.silu(x)\n",
    "        # product of input shape: \n",
    "        x = nn.Dense(features=np.prod(self.input_shape))(x)\n",
    "        x = x.reshape((batch_size, *self.input_shape))  # Reshape back to the original image shape\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn it into a conditional problem! given class\n",
    "backbone = MLP(input_shape=(28, 28,1))\n",
    "velocity_model = VelocityModel(\n",
    "    backbone=backbone,\n",
    "    d_t_embedding=64,  \n",
    ")\n",
    "# explain randomness and keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that input and output indeed have the same shape\n",
    "# TODO: Initialize the model and check output and input shapes are the same\n",
    "key = jax.random.PRNGKey(0)\n",
    "out, params = velocity_model.init_with_output(\n",
    "    key, \n",
    "    jnp.array(x_batch), \n",
    "    jnp.array([0.1]*batch_size),\n",
    ")\n",
    "print(out.shape, x_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and let's initialize the optimiser again\n",
    "learning_rate = 1.e-3\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's go back to the flow matching example\n",
    "# we will first generate samples from xt and plot the trajectories\n",
    "import equinox as eqx\n",
    "\n",
    "def pad_t_like_x(t, x):\n",
    "    if isinstance(t, (float, int)):\n",
    "        return t\n",
    "    return jnp.reshape(t, (-1, *([1] * (x.ndim - 1))))\n",
    "\n",
    "def sample_xt(x0, x1, t):\n",
    "    t = pad_t_like_x(t, x0)\n",
    "    # TODO: write down xt\n",
    "    xt = t * x1 + (1-t) * x0\n",
    "    return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's plot the trajectories\n",
    "# Plot trajectories\n",
    "t = jnp.linspace(0, 1, 10)\n",
    "\n",
    "x0 = jax.random.normal(key, images[0].shape)\n",
    "x1 = images[3]\n",
    "xt = jnp.stack([sample_xt(x0, x1, t_) for t_ in t]) \n",
    "\n",
    "fig, axs = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(xt[i][:,:,0], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f't={t[i]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Write loss function\n",
    "# Now let's compute the loss function\n",
    "def get_conditional_flow(x0,x1,t,xt,): \n",
    "    del t, xt\n",
    "    diff = x1 - x0\n",
    "    return diff\n",
    "\n",
    "def loss_fn(params, x0, x1, t, velocity_model):\n",
    "    xt = sample_xt(x0, x1, t)\n",
    "    ut = get_conditional_flow(x0, x1, t, xt)\n",
    "    vt = velocity_model.apply(params, xt, t,)\n",
    "    return jnp.mean((vt-ut)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and define the training step again\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def train_step(params, opt_state, x0, x, t_batch, velocity_model, optimizer):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, x0, x, t_batch,  velocity_model)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling solving the ODE\n",
    "\n",
    "import diffrax as dfx\n",
    "\n",
    "@eqx.filter_jit\n",
    "def sample(params, velocity_model, x0, dt:float= 0.01,):\n",
    "    original_shape = x0.shape\n",
    "    def velocity(t, x, args):\n",
    "        x = x.reshape(original_shape)\n",
    "        t = jnp.atleast_1d(t)\n",
    "        t = jnp.repeat(t, original_shape[0])\n",
    "        return velocity_model.apply(params, x, t,).reshape(-1)\n",
    "    term = dfx.ODETerm(velocity)\n",
    "    solver = dfx.Euler()\n",
    "    sol = dfx.diffeqsolve(term, solver, 0., 1., dt, x0.reshape(-1))\n",
    "    (y,) = sol.ys\n",
    "    return y.reshape(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_image_grid(images, grid_size=(8, 8), figsize=(10, 10), suptitle=None):\n",
    "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=figsize)\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(images):\n",
    "            ax.imshow(images[i][:,:,0], cmap='gray')\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    if suptitle is not None:\n",
    "        fig.suptitle(suptitle)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_steps = 6_000\n",
    "fcn_train_loss = []\n",
    "with tqdm(total=num_steps, desc='Training', unit='step') as pbar:\n",
    "    for step in range(num_steps):\n",
    "        key, subkey1, subkey2 = jax.random.split(key, 3)\n",
    "        try:\n",
    "            images, labels = next(train_loader)\n",
    "        except StopIteration:\n",
    "            train_loader = iter(train_dataloader)\n",
    "            images, labels = next(train_loader)\n",
    "        images, labels = jnp.array(images), jnp.array(labels)\n",
    "        t_batch = jax.random.uniform(subkey1, (len(images),))\n",
    "        x0 = jax.random.normal(subkey2, images.shape)\n",
    "        params, opt_state, loss = train_step(params, opt_state, x0, images, t_batch, velocity_model, optimizer)\n",
    "        fcn_train_loss.append(loss)\n",
    "        pbar.set_postfix(loss=loss)\n",
    "        pbar.update(1)\n",
    "        if step % 500 == 0:\n",
    "            x1 = sample(params, velocity_model, x0[:64], dt=0.01)\n",
    "            plot_image_grid(x1, suptitle=f'Step {step}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fcn_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a convolutional neural network instead -> add Unet reference\n",
    "from flax.linen import Conv, ConvTranspose\n",
    "class ConvBlock(nn.Module):\n",
    "    features: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = Conv(features=self.features, kernel_size=(3, 3), padding='SAME')(x)\n",
    "        x = nn.silu(x)\n",
    "        x = Conv(features=self.features, kernel_size=(3, 3), padding='SAME')(x)\n",
    "        x = nn.silu(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x, t):\n",
    "        # Downsampling path\n",
    "        c1 = ConvBlock(features=32)(x)\n",
    "        c1 = x + t[:,None,None,]\n",
    "        p1 = nn.max_pool(c1, (2, 2), strides=(2, 2), padding='SAME')\n",
    "        \n",
    "        c2 = ConvBlock(features=64)(p1)\n",
    "        p2 = nn.max_pool(c2, (2, 2), strides=(2, 2), padding='SAME')\n",
    "        \n",
    "        b = ConvBlock(features=64)(p2)\n",
    "        # Upsampling path\n",
    "       \n",
    "        u2 = ConvTranspose(features=64, kernel_size=(2, 2), strides=(2, 2))(b)\n",
    "        u2 = jnp.concatenate([u2, c2], axis=-1)\n",
    "        u2 = ConvBlock(features=64)(u2)\n",
    "       \n",
    "        u1 = ConvTranspose(features=64, kernel_size=(2, 2), strides=(2, 2))(u2)\n",
    "        u1 = jnp.concatenate([u1, c1], axis=-1)\n",
    "        u1 = ConvBlock(features=64)(u1)\n",
    "        \n",
    "        # Output layer\n",
    "        outputs = Conv(features=1, kernel_size=(1, 1))(u1)\n",
    "        \n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = UNet()\n",
    "velocity_model = VelocityModel(\n",
    "    backbone=backbone,\n",
    "    d_t_embedding=64,  \n",
    "    residual=False,\n",
    ")\n",
    "# explain randomness and keys\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "out, params = velocity_model.init_with_output(\n",
    "    key, \n",
    "    jnp.array(x_batch), \n",
    "    jnp.array([0.1]*batch_size),\n",
    ")\n",
    "learning_rate = 1.e-3\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_steps = 6_000\n",
    "cnn_train_loss = []\n",
    "with tqdm(total=num_steps, desc='Training', unit='step') as pbar:\n",
    "    for step in range(num_steps):\n",
    "        key, subkey1, subkey2 = jax.random.split(key, 3)\n",
    "        try:\n",
    "            images, labels = next(train_loader)\n",
    "        except StopIteration:\n",
    "            train_loader = iter(train_dataloader)\n",
    "            images, labels = next(train_loader)\n",
    "        images, labels = jnp.array(images), jnp.array(labels)\n",
    "        t_batch = jax.random.uniform(subkey1, (len(images),))\n",
    "        x0 = jax.random.normal(subkey2, images.shape)\n",
    "        params, opt_state, loss = train_step(params, opt_state, x0, images, t_batch, velocity_model, optimizer)\n",
    "        cnn_train_loss.append(loss)\n",
    "        pbar.set_postfix(loss=loss)\n",
    "        pbar.update(1)\n",
    "        if step % 500 == 0:\n",
    "            x1 = sample(params, velocity_model, x0[:64], dt=0.01)\n",
    "            plot_image_grid(x1, suptitle=f'Step {step}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fcn_train_loss)\n",
    "plt.plot(cnn_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try classifier on generated samples, how does the loss correlate with classifier accuracy? Some times small differences on loss are not big differences in perception!\n",
    "# how would you build a conditional generative model so that we chose to generate just 2's or 8's?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
